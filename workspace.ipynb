{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device:  cuda\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib qt\n",
    "\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import sklearn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torchvision.transforms import v2 as transforms\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from networkAlignmentAnalysis.models.registry import get_model\n",
    "from networkAlignmentAnalysis.datasets import get_dataset\n",
    "from networkAlignmentAnalysis.experiments.registry import get_experiment\n",
    "from networkAlignmentAnalysis import utils\n",
    "from networkAlignmentAnalysis import files\n",
    "from networkAlignmentAnalysis import train\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('using device: ', DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# 1.1. include additional AlignmentModel methods stored in extra class in base model\n",
    "# 5. SLURM!!!!\n",
    "\n",
    "# Basic alignment_comparison Analyses (or maybe for alignment_stats):\n",
    "# - compare initial to final alignment...\n",
    "# - compare initial alignment to delta weight norm...\n",
    "# - observe alignment of delta weight\n",
    "# - compare alignment to outgoing delta weight norm!\n",
    "\n",
    "# Eigenfeature analyses:\n",
    "# done: - start by just looking at amplitude of activity on each eigenvector within each layer\n",
    "# done: - Determine contribution of each eigenfeature on performance with a eigenvector dropout experiment\n",
    "# - Measure beta_adversarial (figure out how adversarial examples map onto eigenvectors)\n",
    "\n",
    "# forward_eigenvector_dropout is slow... maybe because cpu->gpu overhead? \n",
    "\n",
    "# alignmentShaping.ipynb has an adversarial experiment worth looking at\n",
    "# need to integrate manual shaping!!!!\n",
    "\n",
    "# Consider Valentin's idea about measuring an error threshold given signal and noise for a given level of alignment\n",
    "# e.g. plot a 2d heatmap comparing the noise amplitude and the average alignment\n",
    "# and then think about how to apply this to network design...\n",
    "\n",
    "# convert batch_cov to allow for batch_corr too (and make it \"smart\" with zero-var handling)\n",
    "# integrate batched alignment into pipeline  (there's test code in the tests directory)\n",
    "\n",
    "# Experiment Idea:\n",
    "# train a few networks on a task- show that you can predict the class from the loadings onto eigenvectors of hidden layers.\n",
    "# - see if this works for networks trained with a different regularizer (e.g. compare dropout, weight-decay, and none!)\n",
    "# J: equalize class numbers\n",
    "# -- can also use quadratic discriminant analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_parameters = dict(\n",
    "    out_channels=3,\n",
    ")\n",
    "dataset = get_dataset('MNIST', build=True, transform_parameters=transform_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024, 1, 28, 28])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images, labels = next(iter(dataset.train_loader))\n",
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Compose(\n",
       "      ToImage()\n",
       "      ToDtype(scale=True)\n",
       "      Normalize(mean=[0.1307], std=[0.3081], inplace=False)\n",
       "      Grayscale(num_output_channels=3)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epoch: 100%|██████████| 10/10 [00:37<00:00,  3.76s/it]\n",
      "100%|██████████| 10/10 [00:02<00:00,  4.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(95.9441, device='cuda:0')]\n"
     ]
    }
   ],
   "source": [
    "model_name = 'MLP'\n",
    "dataset_name = 'MNIST'\n",
    "\n",
    "net = get_model(model_name, build=True, dataset=dataset_name, dropout=0.5).to(DEVICE)\n",
    "\n",
    "loader_parameters = dict(\n",
    "    shuffle=True,\n",
    ")\n",
    "dataset = get_dataset(dataset_name, build=True, transform_parameters=net, loader_parameters=loader_parameters, device=DEVICE)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "\n",
    "results = train.train([net], [optimizer], dataset, num_epochs=10, alignment=False)\n",
    "test_results = train.test([net], dataset, train=False, alignment=False)\n",
    "\n",
    "# dropout_results = train.eigenvector_dropout([net], dataset, [eigenvalue], [eigenvector], train_set=False, by_layer=True)\n",
    "\n",
    "plt.close('all')\n",
    "plt.plot(results['accuracy'])\n",
    "plt.show()\n",
    "\n",
    "print(test_results['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 15.69it/s]\n",
      "4it [00:00, 27.02it/s]\n"
     ]
    }
   ],
   "source": [
    "inputs, labels = net._process_collect_activity(dataset.test_loader)\n",
    "beta, eigenvalues, eigenvectors = net.measure_eigenfeatures(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:08<00:00,  1.19it/s]\n"
     ]
    }
   ],
   "source": [
    "fgsm_transform = lambda x: x\n",
    "\n",
    "def fgsm_attack(image, epsilon, data_grad, transform, sign):\n",
    "    # Collect the element-wise sign of the data gradient\n",
    "    if sign:\n",
    "        data_grad = data_grad.sign()\n",
    "    else:\n",
    "        data_grad = data_grad.clone()\n",
    "    # Create the perturbed image by adjusting each pixel of the input image\n",
    "    perturbed_image = image + epsilon*data_grad\n",
    "    # Adding clipping to maintain [0,1] range\n",
    "    perturbed_image = transform(perturbed_image)\n",
    "    # Return the perturbed image\n",
    "    return perturbed_image\n",
    "\n",
    "def get_beta(inputs, eigenvectors):\n",
    "    betas = [input.cpu() @ evec for input, evec in zip(inputs, eigenvectors)]\n",
    "    # betas = [torch.sqrt(torch.mean(beta**2, dim=0)) for beta in betas]\n",
    "    return betas\n",
    "\n",
    "@utils.test_nets\n",
    "def test(nets, dataset, epsilon, eigenvectors, sign=True, train=True):\n",
    "    num_eps = len(epsilon)\n",
    "    num_nets = len(nets)\n",
    "    accuracy = torch.zeros((num_nets, num_eps))\n",
    "    examples = [[[] for _ in range(num_eps)] for _ in range(num_nets)]\n",
    "    betas = [[torch.zeros((num_nets, evec.size(0))) for evec in eigenvectors[0]]\n",
    "             for _ in range(num_eps)]\n",
    "\n",
    "    # dataloader\n",
    "    dataloader = dataset.train_loader if train else dataset.test_loader\n",
    "\n",
    "    for batch in tqdm(dataloader):\n",
    "        input, labels = dataset.unwrap_batch(batch)\n",
    "        \n",
    "        inputs = [input.clone() for _ in range(num_nets)]\n",
    "\n",
    "        for input in inputs:\n",
    "            input.requires_grad = True\n",
    "\n",
    "        # Forward pass the data through the model\n",
    "        outputs = [net(input, store_hidden=True) for net, input in zip(nets, inputs)]\n",
    "        input_to_layers = [net.get_layer_inputs(input, precomputed=True) for net in nets]\n",
    "        init_preds = [torch.argmax(output,axis=1) for output in outputs] # find true prediction\n",
    "        least_likely = [torch.argmin(output,axis=1) for output in outputs] # find least likely digit according to model\n",
    "        \n",
    "        c_betas = utils.transpose_list([get_beta(input, evec) for input, evec in zip(input_to_layers, eigenvectors)])\n",
    "        s_betas = [torch.stack(cb) for cb in c_betas]\n",
    "\n",
    "        # Calculate the loss\n",
    "        loss = [dataset.measure_loss(output, labels) for output in outputs]\n",
    "        # loss = dataset.measure_loss(output, least_likely)\n",
    "\n",
    "        # Zero all existing gradients\n",
    "        for net in nets:\n",
    "            net.zero_grad()\n",
    "\n",
    "        # Calculate gradients of model in backward pass\n",
    "        for l in loss:\n",
    "            l.backward()\n",
    "\n",
    "        # Collect datagrad\n",
    "        data_grads = [input.grad.data for input in inputs]\n",
    "        \n",
    "        for epsidx, eps in enumerate(epsilon):\n",
    "            \n",
    "            # Call FGSM Attack\n",
    "            perturbed_inputs = [fgsm_attack(input, eps, data_grad, fgsm_transform, sign)\n",
    "                                for input, data_grad in zip(inputs, data_grads)]\n",
    "\n",
    "            # Re-classify the perturbed image\n",
    "            outputs = [net(perturbed_input, store_hidden=True)\n",
    "                       for net, perturbed_input in zip(nets, perturbed_inputs)]\n",
    "            input_to_layers = [net.get_layer_inputs(perturbed_input, precomputed=True)\n",
    "                               for net, perturbed_input in zip(nets, perturbed_inputs)]\n",
    "            c_eps_betas = utils.transpose_list([get_beta(input, evec) for input, evec in zip(input_to_layers, eigenvectors)])\n",
    "            s_eps_betas = [torch.stack(ceb) for ceb in c_eps_betas]\n",
    "            d_eps_betas = [sebeta - sbeta for sebeta, sbeta in zip(s_eps_betas, s_betas)]\n",
    "            rms_betas = [torch.sqrt(torch.mean(db**2, dim=1)) for db in d_eps_betas]\n",
    "\n",
    "            for ii, rbeta in enumerate(rms_betas):\n",
    "                betas[epsidx][ii] += rbeta\n",
    "\n",
    "            # Check for success\n",
    "            final_preds = [torch.argmax(output, axis=1) for output in outputs]\n",
    "            accuracy[:, epsidx] += torch.tensor([sum(final_pred==labels).cpu() for final_pred in final_preds])\n",
    "            \n",
    "            # Idx where adversarial example worked\n",
    "            idx_success = [torch.where((init_pred==labels) & (final_pred != labels))[0].cpu()\n",
    "                           for init_pred, final_pred in zip(init_preds, final_preds)]\n",
    "            \n",
    "            adv_exs = [perturbed_input.detach().cpu().numpy() for perturbed_input in perturbed_inputs]\n",
    "            for ii, (adv_ex, idx, init_pred, final_pred) in enumerate(zip(adv_exs, idx_success, init_preds, final_preds)):\n",
    "                examples[ii][epsidx].append((init_pred[idx], final_pred[idx], adv_ex[idx]))\n",
    "\n",
    "    # Calculate final accuracy for this epsilon\n",
    "    accuracy = accuracy / float(len(dataloader.dataset))\n",
    "\n",
    "    # Average across betas\n",
    "    betas = [[cb / float(len(dataloader.dataset)) for cb in beta] for beta in betas]\n",
    "        \n",
    "    # Return the accuracy and an adversarial example\n",
    "    return accuracy, betas, examples\n",
    "\n",
    "\n",
    "epsilons = np.linspace(0,1,31)\n",
    "# epsilons = np.hstack((0, np.logspace(2,4,5)))\n",
    "# epsilons = np.hstack((0, np.linspace(10,100000,21)))\n",
    "sign = True\n",
    "\n",
    "num_eps = len(epsilons)\n",
    "num_nets = len([net])\n",
    "\n",
    "prtAccuracy = torch.zeros((num_eps, num_nets))\n",
    "newAccuracy = torch.zeros((num_eps, num_nets))\n",
    "\n",
    "# Run test for each epsilon\n",
    "acc, betas, ex = test([net], dataset, epsilons, [eigenvectors], sign=sign, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['full', 'dropout']\n",
    "\n",
    "plt.close('all')\n",
    "for name, a in zip(names, acc):\n",
    "    plt.plot(epsilons, a, label=name)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "fig, ax = plt.subplots(1, len(betas[0]), figsize=(12, 3), layout='constrained')\n",
    "for ii, beta in enumerate(betas[10]):\n",
    "    ax[ii].plot(range(beta.size(1)), beta[0].detach(), label='full')\n",
    "    ax[ii].plot(range(beta.size(1)), beta[1].detach(), label='dropout')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(betas[10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "networkAlignmentAnalysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
