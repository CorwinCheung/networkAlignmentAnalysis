{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device:  cuda\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib qt\n",
    "\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torchvision.transforms import v2 as transforms\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from networkAlignmentAnalysis.models.registry import get_model\n",
    "from networkAlignmentAnalysis.datasets import get_dataset\n",
    "from networkAlignmentAnalysis.experiments.registry import get_experiment\n",
    "from networkAlignmentAnalysis import utils\n",
    "from networkAlignmentAnalysis import files\n",
    "from networkAlignmentAnalysis import train\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('using device: ', DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# 1.1. include additional AlignmentModel methods stored in extra class in base model\n",
    "\n",
    "# 4. Rewrite existing analysis pipelines\n",
    "# 5. SLURM!!!!\n",
    "\n",
    "# Figure out why convolutional alignment measurement is slow...\n",
    "# still working on if it's possible to speed up measure_alignment for convolutional layers\n",
    "\n",
    "# Basic alignment_comparison Analyses (or maybe for alignment_stats):\n",
    "# - compare initial to final alignment...\n",
    "# - compare initial alignment to delta weight norm...\n",
    "# - observe alignment of delta weight\n",
    "# - compare alignment to outgoing delta weight norm!\n",
    "\n",
    "# Eigenfeature analyses:\n",
    "# done: - start by just looking at amplitude of activity on each eigenvector within each layer\n",
    "# - Determine contribution of each eigenfeature on performance with a eigenvector dropout experiment\n",
    "# - Measure beta_adversarial (figure out how adversarial examples map onto eigenvectors)\n",
    "\n",
    "# alignmentShaping.ipynb has an adversarial experiment worth looking at\n",
    "\n",
    "# Consider Valentin's idea about measuring an error threshold given signal and noise for a given level of alignment\n",
    "# e.g. plot a 2d heatmap comparing the noise amplitude and the average alignment\n",
    "# and then think about how to apply this to network design..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'CNN2P2'\n",
    "dataset_name = 'MNIST'\n",
    "\n",
    "net = get_model(model_name, build=True, dataset=dataset_name).to(DEVICE)\n",
    "dataset = get_dataset(dataset_name, build=True, transform_parameters=net, device=DEVICE)\n",
    "\n",
    "# optimizer = torch.optim.Adam(net.parameters(), lr=1e-2)\n",
    "results = train.train([net], [optimizer], dataset, num_epochs=100, alignment=False)\n",
    "\n",
    "# beta, eigenvalue, eigenvector = net.measure_eigenfeatures(dataset.test_loader)\n",
    "# dropout_results = train.eigenvector_dropout([net], dataset, [eigenvalue], [eigenvector], train_set=False, by_layer=True)\n",
    "\n",
    "# plt.close('all')\n",
    "# plt.plot(results['accuracy'])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# places that use 'unfold' or should use it\n",
    "# -- done -- AN.get_alignment_weights()\n",
    "# -- done --AN.forward_eigenvector.dropout() # --- doesn't use it but it should!!! --- \n",
    "# -- done -- AN.measure_eigenfeatures()\n",
    "# AN.measure_class_eigenfeatures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164 ms ± 3.65 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "188 ms ± 101 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# B, D, S, C = 1024, 25, 784, 32\n",
    "B, D, S, C = 1024, 800, 196, 64\n",
    "input = torch.normal(0, 1, (B, D, S)).to(DEVICE)\n",
    "weight = torch.normal(0, 1, (C, D)).to(DEVICE)\n",
    "\n",
    "def get_align_usual(input, weight):\n",
    "    var_stride = torch.mean(torch.var(input, dim=1), dim=0)\n",
    "    align_stride = torch.stack([utils.alignment(input[:, :, i], weight) for i in range(S)], dim=1)\n",
    "    return utils.weighted_average(align_stride, var_stride.view(1, -1), 1, ignore_nan=True)\n",
    "    \n",
    "def get_align_new(input, weight):\n",
    "    var_stride = torch.mean(torch.var(input, dim=1), dim=0)\n",
    "    cc = utils.batch_cov(input.transpose(0, 2))\n",
    "    rq = torch.sum(torch.matmul(weight, cc) * weight, axis=2) / torch.sum(weight * weight, axis=1)\n",
    "    prq = rq / torch.diagonal(cc, dim1=1, dim2=2).sum(1, keepdim=True)\n",
    "    return utils.weighted_average(prq, var_stride.view(-1, 1), 0, ignore_nan=True)\n",
    "\n",
    "au = get_align_usual(input, weight)\n",
    "an = get_align_new(input, weight)\n",
    "\n",
    "%timeit _ = get_align_usual(input, weight)\n",
    "%timeit _ = get_align_new(input, weight)\n",
    "\n",
    "print(torch.allclose(au, an))\n",
    "\n",
    "\n",
    "# convert batch_cov to allow for batch_corr too (and make it \"smart\" with zero-var handling)\n",
    "# integrate batched alignment into pipeline\n",
    "# check all convolutional code!!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 25, 784])\n",
      "torch.Size([1024, 800, 196])\n",
      "torch.Size([1024, 3136])\n",
      "torch.Size([1024, 128])\n"
     ]
    }
   ],
   "source": [
    "images, labels = dataset.unwrap_batch(next(iter(dataset.test_loader)))\n",
    "\n",
    "inputs = net.get_layer_inputs(images, precomputed=False)\n",
    "processed = net._preprocess_inputs(inputs)\n",
    "processed = [p.cpu() for p in processed]\n",
    "\n",
    "for i in processed:\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# integrate the changes in utils (e.g. smart_pca into _measure_layer_eigenfeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'CNN2P2'\n",
    "dataset_name = 'MNIST'\n",
    "\n",
    "net = get_model(model_name, build=True, dataset=dataset_name).to(DEVICE)\n",
    "dataset = get_dataset(dataset_name, build=True, transform_parameters=net, loader_parameters=dict(batch_size=128), device=DEVICE)\n",
    "\n",
    "# optimizer = torch.optim.Adam(net.parameters(), lr=1e-2)\n",
    "# results = train.train([net], [optimizer], dataset, num_epochs=10, alignment=True)\n",
    "\n",
    "# plt.close('all')\n",
    "# plt.plot(results['accuracy'])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "layer_idx = 0\n",
    "lalign = results['alignment'][layer_idx][0].T\n",
    "x = torch.arange(0, lalign.size(1)).view(1, -1).expand(lalign.size(0), -1)\n",
    "plt.close('all')\n",
    "# plt.scatter(x.flatten(), lalign.flatten(), s=3, c=('k', 0.1))\n",
    "plt.plot(x[0], lalign.T, linewidth=1, color=('k', 0.4))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:03<00:00, 23.06it/s]\n",
      "1it [02:30, 150.37s/it]"
     ]
    }
   ],
   "source": [
    "beta, evals, evecs = net.measure_eigenfeatures(dataset.test_loader, with_updates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = dataset.unwrap_batch(next(iter(dataset.test_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = net.forward_eigenvector_dropout(images, evals, evecs, [[0] for _ in range(net.num_alignment_layers())], net.get_alignment_layer_indices())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "networkAlignmentAnalysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
