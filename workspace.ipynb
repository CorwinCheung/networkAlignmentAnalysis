{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device:  cuda\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torchvision import models, transforms\n",
    "\n",
    "from networkAlignmentAnalysis import utils\n",
    "from networkAlignmentAnalysis import datasets\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('using device: ', DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The LAYER_REGISTRY contains meta parameters for each type of layer used in alignment networks\n",
    "# each layer type is associated with a few features, including:\n",
    "# name (string): just for completeness, will only be used for plotting\n",
    "# layer-handle (lambda method): takes as input a registered layer and returns the part of that layer\n",
    "#                               to perform alignment methods on. For example, if a registered layer\n",
    "#                               is layer=nn.Sequential(nn.Linear(10,10), nn.Dropout()), then the layer\n",
    "#                               handle should be: lambda layer: layer[0])\n",
    "# alignment_method (callable): the method used to measure alignment for a particular layer\n",
    "# Note: as of writing this, I only have nn.Linear and nn.Conv2d here, but this will start to be more\n",
    "# useful and meaningful when reusing typical combinations of layers as a single registered \"layer\" \n",
    "# that include things like dropout, pooling, nonlinearities, etc.\n",
    "REGISTRY_REQUIREMENTS = ['name', 'layer_handle', 'alignment_method', 'ignore']\n",
    "LAYER_REGISTRY = {\n",
    "    nn.Linear: {\n",
    "        'name': 'linear', \n",
    "        'layer_handle': lambda layer:layer, \n",
    "        'alignment_method': utils.alignment_linear,\n",
    "        'ignore': False,\n",
    "        },\n",
    "\n",
    "    nn.Conv2d: {\n",
    "        'name': 'conv2d', \n",
    "        'layer_handle': lambda layer:layer, \n",
    "        'alignment_method': utils.alignment_convolutional,\n",
    "        'ignore': False,\n",
    "        },\n",
    "}\n",
    "\n",
    "def default_metaprms_ignore(name):\n",
    "    \"\"\"convenience method for named metaparameters to be ignored\"\"\"\n",
    "    metaparameters = {\n",
    "        'name': name,\n",
    "        'layer_handle': None,\n",
    "        'alignment_method': None,\n",
    "        'ignore': True\n",
    "    }\n",
    "    return metaparameters\n",
    "\n",
    "def default_metaprms_linear(index, name='linear'):\n",
    "    \"\"\"convenience method for named metaparameters in a linear layer packaged in a sequential\"\"\"\n",
    "    metaparameters = {\n",
    "        'name': name,\n",
    "        'layer_handle': lambda layer: layer[index],\n",
    "        'alignment_method': utils.alignment_linear,\n",
    "        'ignore': False,\n",
    "    }\n",
    "    return metaparameters\n",
    "\n",
    "def default_metaprms_conv2d(index, name='conv2d'):\n",
    "    \"\"\"convenience method for named metaparameters in a conv2d layer packaged in a sequential\"\"\"\n",
    "    metaparameters = {\n",
    "        'name': name,\n",
    "        'layer_handle': lambda layer: layer[index],\n",
    "        'alignment_method': utils.alignment_convolutional,\n",
    "        'ignore': False,\n",
    "    }\n",
    "    return metaparameters\n",
    "\n",
    "def check_metaparameters(metaparameters, throw=True):\n",
    "    \"\"\"validate whether metaparameters is a dictionary containing the required keys for an alignment network\"\"\"\n",
    "    if not all([required in metaparameters for required in REGISTRY_REQUIREMENTS]):\n",
    "        if throw:\n",
    "            raise ValueError(f\"metaparameters are missing required keys, it requires all of the following: {REGISTRY_REQUIREMENTS}\")\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def check_registry():\n",
    "    for layer_type, metaparameters in LAYER_REGISTRY:\n",
    "        if not check_metaparameters(metaparameters, throw=False):\n",
    "            raise ValueError(f\"Layer type: {layer_type} from the `LAYER_REGISTRY` is missing metaparameters. \"\n",
    "                            \"It requires all of the following: {REGISTRY_REQUIREMENTS}\")\n",
    "\n",
    "class AlignmentNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    This is the base class for a neural network used for alignment-related experiments. \n",
    "\n",
    "    The point of all the wrangling of standard torch workflows in this class is to make \n",
    "    it easy to perform all the alignment-related computations for networks with different\n",
    "    architectures without having to rewrite similar code over and over again. In this way,\n",
    "    the user only needs to add a layer type to the **LAYER_REGISTRY** in this file and\n",
    "    then alignment methods can be automatically applied. \n",
    "\n",
    "    The forward method of **AlignmentNetwork** passes the input (*x*) through each registered\n",
    "    layer of the network in order of it's registration. If hidden activations are requested, then\n",
    "    the output of each registered layer is saved. The alignment methods are applied to the \n",
    "    hidden activation at the output of layer L-1 and the weights of layer L. \n",
    "\n",
    "    Note: some shape wrangling (like that which happens between a convolutional layer and a\n",
    "    linear layer are often treated as a nn.Module layer), but these don't require alignment-\n",
    "    related processing. To use these, set 'ignore' of the metaparameters to True. Alternatively,\n",
    "    you can append them to the last component of a layer.\n",
    "\n",
    "    A layer in the layer_registry should have the following properties:\n",
    "    1. Be a child of the nn.Module class with a forward method\n",
    "    2. Have at most one \"relevant\" processing stage with weights for measuring alignment\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__() # register it as a nn.Module\n",
    "        self.layers = nn.ModuleList() # a list of all modules in the forward pass\n",
    "        self.metaparameters = [] # list of dictionaries containing metaparameters for each layer\n",
    "        self.hidden = [] # list of tensors containing hidden activations\n",
    "\n",
    "    def register_layer(self, layer, verbose=True, **kwargs):\n",
    "        \"\"\"\n",
    "        register_layer adds a **layer** to the network's module list and it's associated metaparameters\n",
    "        for determining what kind of aligment-related processing is done on the layer\n",
    "\n",
    "        by default, the layer is used as a key to lookup the metaparameters from the **LAYER_REGISTRY**. \n",
    "        kwargs can update keys in the metaparameters. If the layer class is not registered, then all \n",
    "        metaparameters must be provided as kwargs.\n",
    "         \n",
    "        Required kwargs are: name, layer_handle, alignment_method, ignore, ...\n",
    "        \"\"\"\n",
    "        if not isinstance(layer, nn.Module):\n",
    "            raise TypeError(f\"provided layer is of type: {type(layer)}, but only nn.Module objects are permitted!\")\n",
    "        \n",
    "        metaparameters = LAYER_REGISTRY.get(type(layer), {})\n",
    "        for metaprms in REGISTRY_REQUIREMENTS:\n",
    "            # for each possible entry in layer metaparameters, check if it's provided, not none, then update it\n",
    "            if metaprms in kwargs and kwargs[metaprms] is not None:\n",
    "                metaparameters[metaprms]=kwargs[metaprms]\n",
    "        \n",
    "        # check whether metaparameters contain the correct keys\n",
    "        check_metaparameters(metaparameters, throw=True)\n",
    "        \n",
    "        # add layer to network\n",
    "        self.layers.append(layer)\n",
    "        self.metaparameters.append(metaparameters)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Added a {metaparameters['name']} layer to the network\")\n",
    "\n",
    "\n",
    "    def forward(self, x, store_hidden=False):\n",
    "        \"\"\"standard forward pass of all layers with option of storing hidden activations (and output)\"\"\"\n",
    "        self.hidden = [] # always reset so as to not keep a previous forward pass accidentally\n",
    "        for layer, metaprms in zip(self.layers, self.metaparameters):\n",
    "            x = layer(x) # pass through next layer\n",
    "            if store_hidden and not metaprms['ignore']: \n",
    "                self.hidden.append(x)\n",
    "        return x\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def get_activations(self, x=None, precomputed=False):\n",
    "        \"\"\"convenience method for getting list of intermediate activations throughout the network\"\"\"\n",
    "        if not precomputed and x is not None:\n",
    "            _ = self.forward(x, store_hidden=True)\n",
    "        else:\n",
    "            raise ValueError(\"x needs to be provided if precomputed is False\")\n",
    "        return self.hidden\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def get_alignment_layers(self):\n",
    "        \"\"\"convenience method for retrieving registered layers for alignment measurements throughout the network\"\"\"\n",
    "        layers = []\n",
    "        for layer, metaprms in zip(self.layers, self.metaparameters):\n",
    "            if not metaprms['ignore']:\n",
    "                layers.append(metaprms['layer_handle'](layer))\n",
    "        return layers\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def get_alignment_metaparameters(self):\n",
    "        \"\"\"convenience method for retrieving registered layers for alignment measurements throughout the network\"\"\"\n",
    "        metaparameters = []\n",
    "        for metaprms in self.metaparameters:\n",
    "            if not metaprms['ignore']:\n",
    "                metaparameters.append(metaprms)\n",
    "        return metaparameters\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def get_alignment_weights(self):\n",
    "        \"\"\"convenience method for retrieving registered weights for alignment measurements throughout the network\"\"\"\n",
    "        return [layer.weight for layer in self.get_alignment_layers()]\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def compare_weights(self, weights):\n",
    "        current_weights = self.get_alignment_weights()\n",
    "        delta_weights = []\n",
    "        for iw, cw in zip(weights, current_weights):\n",
    "            delta_weights.append(torch.norm(cw.flatten(1), iw.flatten(1), dim=1))\n",
    "        return delta_weights\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def measure_alignment(self, x, precomputed=False, method='alignment'):\n",
    "        activations = self.get_activations(x=x, precomputed=precomputed)\n",
    "        alignment = []\n",
    "        for activation, layer, metaprms in zip(activation, self.get_alignment_layers(), self.get_alignment_metaparameters()):\n",
    "            alignment.append(metaprms['alignment_method'](activation, layer, method=method))\n",
    "        return alignment\n",
    "\n",
    "\n",
    "class MLP(AlignmentNetwork):\n",
    "    def __init__(self, verbose=True):\n",
    "        super().__init__()\n",
    "\n",
    "        layer1 = nn.Sequential(nn.Linear(784, 100), nn.ReLU())\n",
    "        layer2 = nn.Sequential(nn.Dropout(), nn.Linear(100, 100), nn.ReLU())\n",
    "        layer3 = nn.Sequential(nn.Dropout(), nn.Linear(100, 50), nn.ReLU())\n",
    "        layer4 = nn.Sequential(nn.Dropout(), nn.Linear(50, 10))\n",
    "\n",
    "        self.register_layer(layer1, **default_metaprms_linear(0), verbose=verbose)\n",
    "        self.register_layer(layer2, **default_metaprms_linear(1), verbose=verbose)\n",
    "        self.register_layer(layer3, **default_metaprms_linear(1), verbose=verbose)\n",
    "        self.register_layer(layer4, **default_metaprms_linear(1), verbose=verbose)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added a linear layer to the network\n",
      "Added a linear layer to the network\n",
      "Added a linear layer to the network\n",
      "Added a linear layer to the network\n"
     ]
    }
   ],
   "source": [
    "net = MLP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = transforms.Compose([\n",
    "            transforms.ToTensor(), # first, convert image to PyTorch tensor\n",
    "            transforms.Normalize((0.1307,), (0.3081,)), # normalize inputs\n",
    "            transforms.Lambda(torch.flatten), # convert to vectors\n",
    "        ])\n",
    "trainloader, testloader = datasets.downloadMNIST(preprocess=preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:22<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "x needs to be provided if precomputed is False",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Andrew\\Documents\\GitHub\\networkAlignmentAnalysis\\workspace.ipynb Cell 5\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Andrew/Documents/GitHub/networkAlignmentAnalysis/workspace.ipynb#W6sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Andrew/Documents/GitHub/networkAlignmentAnalysis/workspace.ipynb#W6sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m \u001b[39m# Measure Integration\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Andrew/Documents/GitHub/networkAlignmentAnalysis/workspace.ipynb#W6sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m alignFull\u001b[39m.\u001b[39mappend(net\u001b[39m.\u001b[39;49mmeasure_alignment(images, precomputed\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, method\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39malignment\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Andrew/Documents/GitHub/networkAlignmentAnalysis/workspace.ipynb#W6sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m \u001b[39m# Measure Change in Weights\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Andrew/Documents/GitHub/networkAlignmentAnalysis/workspace.ipynb#W6sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m deltaWeights\u001b[39m.\u001b[39mappend(net\u001b[39m.\u001b[39mcompare_weights(init_weights))\n",
      "File \u001b[1;32mc:\\Users\\Andrew\\AppData\\Local\\miniforge3\\envs\\networkAlignmentAnalysis\\lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[1;32mc:\\Users\\Andrew\\Documents\\GitHub\\networkAlignmentAnalysis\\workspace.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Andrew/Documents/GitHub/networkAlignmentAnalysis/workspace.ipynb#W6sZmlsZQ%3D%3D?line=182'>183</a>\u001b[0m \u001b[39m@torch\u001b[39m\u001b[39m.\u001b[39mno_grad()\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Andrew/Documents/GitHub/networkAlignmentAnalysis/workspace.ipynb#W6sZmlsZQ%3D%3D?line=183'>184</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmeasure_alignment\u001b[39m(\u001b[39mself\u001b[39m, x, precomputed\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, method\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39malignment\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/Andrew/Documents/GitHub/networkAlignmentAnalysis/workspace.ipynb#W6sZmlsZQ%3D%3D?line=184'>185</a>\u001b[0m     activations \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_activations(x\u001b[39m=\u001b[39;49mx, precomputed\u001b[39m=\u001b[39;49mprecomputed)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Andrew/Documents/GitHub/networkAlignmentAnalysis/workspace.ipynb#W6sZmlsZQ%3D%3D?line=185'>186</a>\u001b[0m     alignment \u001b[39m=\u001b[39m []\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Andrew/Documents/GitHub/networkAlignmentAnalysis/workspace.ipynb#W6sZmlsZQ%3D%3D?line=186'>187</a>\u001b[0m     \u001b[39mfor\u001b[39;00m activation, layer, metaprms \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(activation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_alignment_layers(), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_alignment_metaparameters()):\n",
      "File \u001b[1;32mc:\\Users\\Andrew\\AppData\\Local\\miniforge3\\envs\\networkAlignmentAnalysis\\lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[1;32mc:\\Users\\Andrew\\Documents\\GitHub\\networkAlignmentAnalysis\\workspace.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Andrew/Documents/GitHub/networkAlignmentAnalysis/workspace.ipynb#W6sZmlsZQ%3D%3D?line=146'>147</a>\u001b[0m     _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward(x, store_hidden\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Andrew/Documents/GitHub/networkAlignmentAnalysis/workspace.ipynb#W6sZmlsZQ%3D%3D?line=147'>148</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/Andrew/Documents/GitHub/networkAlignmentAnalysis/workspace.ipynb#W6sZmlsZQ%3D%3D?line=148'>149</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mx needs to be provided if precomputed is False\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Andrew/Documents/GitHub/networkAlignmentAnalysis/workspace.ipynb#W6sZmlsZQ%3D%3D?line=149'>150</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhidden\n",
      "\u001b[1;31mValueError\u001b[0m: x needs to be provided if precomputed is False"
     ]
    }
   ],
   "source": [
    "net.to(DEVICE)\n",
    "    \n",
    "# Prepare Training Functions \n",
    "loss_function = nn.CrossEntropyLoss() # Note: this automatically applies softmax...\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=1e-3)\n",
    "# optimizer = torch.optim.Adadelta(net.parameters())\n",
    "\n",
    "# Preallocate summary variables  \n",
    "iterations = 100\n",
    "numTrainingSteps = len(trainloader)*iterations\n",
    "trackLoss = torch.zeros(numTrainingSteps)\n",
    "trackAccuracy = torch.zeros(numTrainingSteps)\n",
    "alignFull = []\n",
    "deltaWeights = []\n",
    "\n",
    "init_weights = net.get_alignment_weights()\n",
    "\n",
    "# Train Network & Measure Integration\n",
    "t = time.time()\n",
    "for epoch in tqdm(range(0, iterations)): \n",
    "    # Set current loss value\n",
    "    currentLoss = 0.0\n",
    "    numBatches = 0\n",
    "    currentCorrect = 0\n",
    "    currentAttempted = 0\n",
    "\n",
    "    for idx,batch in enumerate(trainloader):\n",
    "        cidx = epoch*len(trainloader) + idx\n",
    "        \n",
    "        images, label = batch\n",
    "        images = images.to(DEVICE)\n",
    "        label = label.to(DEVICE)\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Perform forward pass\n",
    "        outputs = net(images)\n",
    "\n",
    "        # Perform backward pass & optimization\n",
    "        loss = loss_function(outputs, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Measure Integration\n",
    "        alignFull.append(net.measure_alignment(images, precomputed=True, method='alignment'))\n",
    "        \n",
    "        # Measure Change in Weights\n",
    "        deltaWeights.append(net.compare_weights(init_weights))\n",
    "\n",
    "        # Track Loss and Accuracy\n",
    "        trackLoss[cidx] = loss.item()\n",
    "        trackAccuracy[cidx] = 100*torch.sum(torch.argmax(outputs,axis=1)==label)/images.shape[0]\n",
    "\n",
    "    # Print statistics for each epoch\n",
    "    print('Loss in epoch %3d: %.3f, Accuracy: %.2f%%.' % (epoch, loss.item(), 100*torch.sum(torch.argmax(outputs,axis=1)==label)/images.shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the BaseNetwork needs alignment and other methods\n",
    "# keep working on MLP here\n",
    "# all the models I've written are in the models/models.py module, will break them out into different modules as I write them!\n",
    "# will probably have to keep updating and copy BaseNetwork and MLP to the appropriate modules, but wanted to \"seed\" them with the target organization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "networkAlignmentAnalysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
