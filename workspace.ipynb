{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device:  cuda\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torchvision.transforms import v2 as transforms\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from networkAlignmentAnalysis.models.registry import get_model\n",
    "from networkAlignmentAnalysis import utils\n",
    "from networkAlignmentAnalysis import datasets\n",
    "from networkAlignmentAnalysis import files\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('using device: ', DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# 1.1. include additional AlignmentModel methods stored in extra class in base model\n",
    "# -- the measure_eigenfeature method is baaaaad -- because it doesn't account for convolutional layers\n",
    "\n",
    "# I should also break apart the measure_eigenfeatures method for better parameter handling\n",
    "# and also to allow use of components of the method in other contexts\n",
    "\n",
    "# 2. Make CIFAR class\n",
    "# 4. Rewrite existing analysis pipelines\n",
    "# 5. SLURM!!!!\n",
    "\n",
    "\n",
    "# Analyses:\n",
    "# - targeted dropout throughout training curves (blue and black in alignmentMNIST.ipynb)\n",
    "# - compare initial to final alignment...\n",
    "# - compare initial alignment to delta weight norm...\n",
    "# - observe alignment of weight norm\n",
    "# - compare alignment to outgoing weight norm!\n",
    "\n",
    "\n",
    "# alignmentShaping.ipynb has an adversarial experiment worth looking at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "base_path = Path(r'C:\\Users\\Andrew\\Documents\\machineLearning\\results\\alignment_comparison\\lr\\MLP\\MNIST\\SGD')\n",
    "res_path = base_path / 'resdir'\n",
    "torch_path = base_path / 'torchdir'\n",
    "small_path = base_path / 'smalldir'\n",
    "diff_path = base_path / 'diffdir'\n",
    "if not res_path.exists(): res_path.mkdir()\n",
    "if not torch_path.exists(): torch_path.mkdir()\n",
    "if not small_path.exists(): small_path.mkdir()\n",
    "if not diff_path.exists(): diff_path.mkdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial load time: 181.21236991882324\n",
      "np save time: 151.89708423614502\n",
      "np load time: 193.31731343269348\n",
      "torch save time: 150.4975814819336\n",
      "torch load time: 156.98896884918213\n"
     ]
    }
   ],
   "source": [
    "def save_each(results, path):\n",
    "    for key, val in results.items():\n",
    "        np.save(path / f\"{key}.npy\", val)\n",
    "\n",
    "def load_each(path):\n",
    "    files = path.rglob('*.*')\n",
    "    results = {}\n",
    "    for f in files:\n",
    "        results[f.stem] = np.load(f, allow_pickle=True).item()\n",
    "        #print(f.stem, f.suffix, type(results[f.stem]))\n",
    "    return results\n",
    "\n",
    "def save_each_torch(results, path):\n",
    "    for key, val in results.items():\n",
    "        torch.save(val, path / f\"{key}.pth\")\n",
    "\n",
    "def load_each_torch(path):\n",
    "    files = path.rglob('*.*')\n",
    "    results = {}\n",
    "    for f in files:\n",
    "        results[f.stem] = torch.load(f)\n",
    "        #print(f.stem, f.suffix, type(results[f.stem]))\n",
    "    return results\n",
    "        \n",
    "# load results dictionary\n",
    "t = time.time()\n",
    "results = np.load(base_path / 'results.npy', allow_pickle=True).item()\n",
    "print('initial load time:', time.time() - t)\n",
    "\n",
    "# save and load each file in results using np.save / np.load\n",
    "t = time.time()\n",
    "save_each(results, res_path)\n",
    "print('np save time:', time.time() - t)\n",
    "t = time.time()\n",
    "res = load_each(res_path)\n",
    "print('np load time:', time.time() - t)\n",
    "\n",
    "# save and load each file in results using torch save / load\n",
    "t = time.time()\n",
    "save_each_torch(results, torch_path)\n",
    "print('torch save time:', time.time() - t)\n",
    "t = time.time()\n",
    "restorch = load_each_torch(torch_path)\n",
    "print('torch load time:', time.time() - t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'alignment', 'delta_weights', 'avgcorr'])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restorch['train_results'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "res_small = deepcopy(restorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in res_small['train_results']:\n",
    "    for i in range(30):\n",
    "        res_small['train_results'][key][i] = res_small['train_results'][key][i][:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_diff = deepcopy(res_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.Size([30, 300, 100]), torch.Size([30, 300, 100]), torch.Size([30, 300, 50]), torch.Size([30, 300, 10])]\n",
      "[torch.Size([30, 300, 100]), torch.Size([30, 300, 100]), torch.Size([30, 300, 50]), torch.Size([30, 300, 10])]\n",
      "[torch.Size([30, 300, 1]), torch.Size([30, 300, 1]), torch.Size([30, 300, 1]), torch.Size([30, 300, 1])]\n"
     ]
    }
   ],
   "source": [
    "to_reshape = ['alignment', 'delta_weights', 'avgcorr']\n",
    "for key in to_reshape:\n",
    "    res_diff['train_results'][key] = utils.condense_values(res_diff['train_results'][key])\n",
    "    print([rd.shape for rd in res_diff['train_results'][key]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch save time: 7.339666128158569\n",
      "torch load time: 7.758648872375488\n"
     ]
    }
   ],
   "source": [
    "# save and load each file in results using torch save / load\n",
    "t = time.time()\n",
    "save_each_torch(res_small, small_path)\n",
    "print('torch save time:', time.time() - t)\n",
    "t = time.time()\n",
    "_ = load_each_torch(small_path)\n",
    "print('torch load time:', time.time() - t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch save time: 0.1612858772277832\n",
      "torch load time: 0.1667790412902832\n"
     ]
    }
   ],
   "source": [
    "# save and load each file in results using torch save / load\n",
    "t = time.time()\n",
    "save_each_torch(res_diff, diff_path)\n",
    "print('torch save time:', time.time() - t)\n",
    "t = time.time()\n",
    "_ = load_each_torch(diff_path)\n",
    "print('torch load time:', time.time() - t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff save time:  0.16904735565185547\n",
      "diff load time:  0.14708733558654785\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "torch.save(res_diff, base_path / 'diff_direct.pth')\n",
    "print('diff save time: ', time.time() - t)\n",
    "\n",
    "\n",
    "t = time.time()\n",
    "xxx = torch.load(base_path / 'diff_direct.pth')\n",
    "print('diff load time: ', time.time() - t)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "networkAlignmentAnalysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
