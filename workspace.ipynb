{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torchvision import models, transforms\n",
    "\n",
    "\n",
    "LAYER_REGISTRY = {\n",
    "    nn.Linear: ('linear', lambda layer: layer.weight.data),\n",
    "    nn.Conv2d: ('conv2d', lambda layer: layer.weight.data),\n",
    "}\n",
    "\n",
    "class BaseNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    This is the base class for a neural network used for alignment-related \n",
    "    experiments. The goal is for networks with specific functions to inherit\n",
    "    methods and properties from the **BaseNetwork** that allow seamless \n",
    "    integration with the general tools required for the project\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__() # register it as a nn.Module\n",
    "        self.layers = nn.ModuleList() # a list of all modules in the forward pass\n",
    "        self.layer_types = [] # list of strings describing the type of the layer\n",
    "        self.layer_weight_handle = [] # list of handles to retrieve the relevant weights of the layer\n",
    "        self.hidden = [] # list of tensors containing hidden activations\n",
    "\n",
    "    def register_layer(self, layer, weight_handle=None, verbose=True):\n",
    "        \"\"\"\n",
    "        register_layer adds a **layer** to the network's module list\n",
    "        the **type** determines what kind of alignment related processing is done on the layer\n",
    "        \"\"\"\n",
    "        layer_type, default_weight_handle = LAYER_REGISTRY.get(type(layer), (None, None))\n",
    "        \n",
    "        if not isinstance(layer, nn.Module):\n",
    "            raise TypeError(f\"provided layer is of type: {type(layer)}, but only nn.Module objects are permitted!\")\n",
    "        \n",
    "        layer_weight_handle = weight_handle if weight_handle is not None else default_weight_handle\n",
    "        \n",
    "        # add layer to network\n",
    "        self.layers.append(layer)\n",
    "        self.layer_types.append(layer_type)\n",
    "        self.layer_weight_handle.append(layer_weight_handle)\n",
    "\n",
    "        if verbose:\n",
    "            if layer_type is not None:\n",
    "                print(f\"Added a {layer_type} layer to the network with the following properties:\\n {layer}\")\n",
    "            else:\n",
    "                print(f\"Added an unknown layer type to the network, it will be used in the forward pass but not processed. Layer props:\\n {layer}\")\n",
    "\n",
    "    def forward(self, x, store_hidden=False):\n",
    "        self.hidden = [] # always reset so as to not keep a previous forward pass accidentally\n",
    "        for layer in self.layers:\n",
    "            x = layer(x) # pass through next layer\n",
    "            if store_hidden: self.hidden.append(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "class MLP(BaseNetwork):\n",
    "    def __init__(self, verbose=True):\n",
    "        super().__init__()\n",
    "\n",
    "        fc1 = nn.Linear(784, 100)\n",
    "        fc2 = nn.Linear(100, 10)\n",
    "        fc3 = nn.Sequential(nn.Linear(10, 10), nn.Linear(10, 10))\n",
    "        self.register_layer(fc1, verbose=verbose)\n",
    "        self.register_layer(fc2, verbose=verbose)\n",
    "        self.register_layer(fc3, weight_handle=lambda layer: layer[0].weight.data, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added a linear layer to the network with the following properties:\n",
      " Linear(in_features=784, out_features=100, bias=True)\n",
      "Added a linear layer to the network with the following properties:\n",
      " Linear(in_features=100, out_features=10, bias=True)\n",
      "Added an unknown layer type to the network, it will be used in the forward pass but not processed. Layer props:\n",
      " Sequential(\n",
      "  (0): Linear(in_features=10, out_features=10, bias=True)\n",
      "  (1): Linear(in_features=10, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "mlp = MLP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the BaseNetwork needs alignment and other methods\n",
    "# keep working on MLP here\n",
    "# all the models I've written are in the models/models.py module, will break them out into different modules as I write them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "networkAlignmentAnalysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
