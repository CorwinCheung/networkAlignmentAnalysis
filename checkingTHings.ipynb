{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1afaac61-4fa7-46a1-9bb0-951fdaccee97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import tools.alignmentAnalysisTools as aat\n",
    "from torchvision import models, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6683b00-82da-45d3-92e0-24dd1c92b1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1)      \n",
    "        self.maxPool = nn.MaxPool2d(kernel_size=3)\n",
    "        self.fc1 = nn.Linear(256, 256) #4608, 512       \n",
    "        self.o = nn.Linear(256, 10) #512, 10\n",
    "\n",
    "        self.layerRegistration = {\n",
    "            'conv1':False,\n",
    "            'conv2':False,\n",
    "            'fc1':True,\n",
    "            'o':True\n",
    "        }\n",
    "        \n",
    "        self.layers = []\n",
    "        self.layers.append(nn.Sequential(\n",
    "            self.conv1,\n",
    "            nn.ReLU(),\n",
    "        ))\n",
    "\n",
    "        self.layers.append(nn.Sequential(\n",
    "            self.conv2,\n",
    "            nn.ReLU(),\n",
    "            self.maxPool\n",
    "        ))\n",
    "        self.layers.append(nn.Sequential(\n",
    "            nn.Flatten(start_dim=1),\n",
    "            self.fc1,\n",
    "            nn.ReLU()\n",
    "        ))\n",
    "        self.layers.append(nn.Sequential(\n",
    "            self.o\n",
    "        ))\n",
    "\n",
    "        self.numLayers = len(self.layers)\n",
    "    \n",
    "    def forward(self, x):        \n",
    "        self.activations = [None]*self.numLayers\n",
    "        for idx, layer in enumerate(self.layers):\n",
    "            x = layer(x)\n",
    "            self.activations[idx]=x\n",
    "        return x\n",
    "\n",
    "    def getNetworkWeights(self,onlyFF=False):\n",
    "        netWeights = [None]*self.numLayers\n",
    "        for \n",
    "        if not onlyFF:\n",
    "            netWeights.append(self.conv1.weight.data.clone().detach())\n",
    "            netWeights.append(self.conv2.weight.data.clone().detach())\n",
    "        netWeights.append(self.fc1.weight.data.clone().detach())\n",
    "        netWeights.append(self.o.weight.data.clone().detach())\n",
    "        return netWeights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64d7318-3804-4b41-a376-7bcad93e0aa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81bdfbd-9f11-42ef-8e81-7b10ed09a47f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b8c6839-655b-4da9-82ac-46db4dcf66ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN2P2(nn.Module):\n",
    "    \"\"\"\n",
    "    CNN with 2 convolutional layers, a max pooling stage, and 2 feedforward layers\n",
    "    Activation function is Relu by default (but can be chosen with hiddenactivation). \n",
    "    Output activation function is identity, because we're using CrossEntropyLoss\n",
    "    \"\"\"\n",
    "    def __init__(self,convActivation=F.relu,linearActivation=F.relu):\n",
    "        super().__init__()\n",
    "        self.numLayers = 4\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1)      \n",
    "        self.maxPool = nn.MaxPool2d(kernel_size=3)\n",
    "        self.fc1 = nn.Linear(256, 256) #4608, 512       \n",
    "        self.o = nn.Linear(256, 10) #512, 10\n",
    "        \n",
    "        self.convActivation=convActivation\n",
    "        self.linearActivation=linearActivation \n",
    "\n",
    "    def forward(self, x):        \n",
    "        self.c1 = self.convActivation(self.conv1(x))\n",
    "        self.c2 = self.maxPool(self.convActivation(self.conv2(self.c1)))\n",
    "        self.f1 = self.linearActivation(self.fc1(torch.flatten(self.c2,1)))\n",
    "        self.out = self.o(self.f1)\n",
    "        return self.out \n",
    "    \n",
    "    def getDropout(self):\n",
    "        return None\n",
    "    \n",
    "    def setDropout(self,dropout):\n",
    "        return None\n",
    "    \n",
    "    def getActivations(self,x):\n",
    "        out = self.forward(x)\n",
    "        activations = []\n",
    "        activations.append(self.c1)\n",
    "        activations.append(self.c2)\n",
    "        activations.append(self.f1)\n",
    "        activations.append(self.out)\n",
    "        return activations\n",
    "    \n",
    "    def getNetworkWeights(self,onlyFF=False):\n",
    "        netWeights = []\n",
    "        if not onlyFF:\n",
    "            netWeights.append(self.conv1.weight.data.clone().detach())\n",
    "            netWeights.append(self.conv2.weight.data.clone().detach())\n",
    "        netWeights.append(self.fc1.weight.data.clone().detach())\n",
    "        netWeights.append(self.o.weight.data.clone().detach())\n",
    "        return netWeights\n",
    "    \n",
    "    def compareNetworkWeights(self, initWeights):\n",
    "        currWeights = self.getNetworkWeights()\n",
    "        deltaWeights = []\n",
    "        for iw,cw in zip(initWeights,currWeights):\n",
    "            iw = torch.flatten(iw,1)\n",
    "            cw = torch.flatten(cw,1)\n",
    "            deltaWeights.append(torch.norm(cw-iw,dim=1))\n",
    "        return deltaWeights\n",
    "        \n",
    "    def measureSimilarity(self,x):\n",
    "        activations = self.getActivations(x)            \n",
    "        similarity = []\n",
    "        similarity.append(torch.mean(aat.similarityConvLayer(x, self.conv1),axis=1))\n",
    "        similarity.append(torch.mean(aat.similarityConvLayer(activations[0], self.conv2),axis=1))\n",
    "        similarity.append(aat.similarityLinearLayer(torch.flatten(activations[1],1), self.fc1))\n",
    "        similarity.append(aat.similarityLinearLayer(activations[2], self.o))\n",
    "        return similarity\n",
    "        \n",
    "    def measureAlignment(self,x):\n",
    "        activations = self.getActivations(x)            \n",
    "        alignment = []\n",
    "        alignment.append(torch.mean(aat.alignmentConvLayer(x, self.conv1),axis=1))\n",
    "        alignment.append(torch.mean(aat.alignmentConvLayer(activations[0], self.conv2),axis=1))\n",
    "        alignment.append(aat.alignmentLinearLayer(torch.flatten(activations[1],1), self.fc1))\n",
    "        alignment.append(aat.alignmentLinearLayer(activations[2], self.o))\n",
    "        return alignment\n",
    "    \n",
    "    def manualShape(self,evals,evecs,DEVICE,evalTransform=None):\n",
    "        if evalTransform is None: evalTransform = lambda x:x\n",
    "            \n",
    "        sbetas = [] # produce signed betas\n",
    "        netweights = self.getNetworkWeights(onlyFF=True)\n",
    "        for evc,nw in zip(evecs,netweights):\n",
    "            nw = nw / torch.norm(nw,dim=1,keepdim=True)\n",
    "            sbetas.append(nw.cpu() @ evc)\n",
    "        \n",
    "        ffLayers = [2,3]\n",
    "        shapedWeights = [[] for _ in range(len(ffLayers))]\n",
    "        for idx in range(len(ffLayers)):\n",
    "            assert np.all(evals[idx]>=0), \"Found negative eigenvalues...\"\n",
    "            cFractionVariance = evals[idx]/np.sum(evals[idx]) # compute fraction of variance explained by each eigenvector\n",
    "            cKeepFraction = evalTransform(cFractionVariance).astype(cFractionVariance.dtype) # make sure the datatype doesn't change, otherwise pytorch einsum will be unhappy\n",
    "            assert np.all(cKeepFraction>=0), \"Found negative transformed keep fractions. This means the transform function has an improper form.\" \n",
    "            assert np.all(cKeepFraction<=1), \"Found keep fractions greater than 1. This is bad practice, design the evalTransform function to have a domain and range within [0,1]\"\n",
    "            weightNorms = torch.norm(netweights[idx],dim=1,keepdim=True) # measure norm of weights (this will be invariant to the change)\n",
    "            evecComposition = torch.einsum('oi,xi->oxi',sbetas[idx],torch.tensor(evecs[idx])) # create tensor composed of each eigenvector scaled to it's contribution in each weight vector\n",
    "            newComposition = torch.einsum('oxi,i->ox',evecComposition,torch.tensor(cKeepFraction)).to(DEVICE) # scale eigenvectors based on their keep fraction (by default scale them by their variance)\n",
    "            shapedWeights[idx] = newComposition / torch.norm(newComposition,dim=1,keepdim=True) * weightNorms\n",
    "        \n",
    "        # Assign new weights to network\n",
    "        self.fc1.weight.data = shapedWeights[0]\n",
    "        self.o.weight.data = shapedWeights[1]\n",
    "    \n",
    "    @staticmethod\n",
    "    def targetedDropout(net,x,idx=None,layer=None,returnFull=False):\n",
    "        assert layer>=0 and layer<=2, \"dropout only works on first three layers\"\n",
    "        c1 = net.convActivation(net.conv1(x))\n",
    "        if layer==0: \n",
    "            fracDropout = len(idx)/c1.shape[1]\n",
    "            c1[:,idx]=0\n",
    "            c1 = c1 * (1 - fracDropout)\n",
    "        c2 = net.maxPool(net.convActivation(net.conv2(c1))) \n",
    "        if layer==1: \n",
    "            fracDropout = len(idx)/c2.shape[1]\n",
    "            c2[:,idx]=0\n",
    "            c2 = c2 * (1 - fracDropout)\n",
    "        f1 = net.linearActivation(net.fc1(torch.flatten(c2,1)))        \n",
    "        if layer==2: \n",
    "            fracDropout = len(idx)/f1.shape[1]\n",
    "            f1[:,idx]=0\n",
    "            f1 = f1 * (1 - fracDropout)\n",
    "        out = net.o(f1)\n",
    "        if returnFull: return c1,c2,f1,out\n",
    "        else: return out\n",
    "    \n",
    "    @staticmethod\n",
    "    def mlTargetedDropout(net,x,idx,layer,returnFull=False):\n",
    "        assert type(idx) is tuple and type(layer) is tuple, \"idx and layer need to be tuples\"\n",
    "        assert len(idx)==len(layer), \"idx and layer need to have the same length\"\n",
    "        npLayer = np.array(layer)\n",
    "        assert len(npLayer)==len(np.unique(npLayer)), \"layer must not have any repeated elements\"\n",
    "        # Do forward pass with targeted dropout\n",
    "        c1 = net.convActivation(net.conv1(x))\n",
    "        if np.any(npLayer==0):\n",
    "            cIndex = idx[npLayer==0]\n",
    "            fracDropout=len(cIndex)/c1.shape[1]\n",
    "            c1[:,cIndex]=0\n",
    "            c1 = c1 * (1 - fracDropout)\n",
    "        c2 = net.maxPool(net.convAcivation(net.conv2(c1)))\n",
    "        if np.any(npLayer==1):\n",
    "            cIndex = idx[npLayer==1]\n",
    "            fracDropout=len(cIndex)/c2.shape[1]\n",
    "            c2[:,cIndex]=0\n",
    "            c2 = c21 * (1 - fracDropout)\n",
    "        f1 = net.linearActivation(net.fc1(torch.flatten(c2,1)))\n",
    "        if np.any(npLayer==2):\n",
    "            cIndex = idx[npLayer==2]\n",
    "            fracDropout = len(cIndex)/f1.shape[1]\n",
    "            f1[:,cIndex]=0\n",
    "            f1 = f1 * (1 - fracDropout)\n",
    "        out = net.o(f1)\n",
    "        if returnFull: return c1,c2,f1,out\n",
    "        else: return out\n",
    "    \n",
    "    @staticmethod\n",
    "    def inputEigenfeatures(net, dataloader, onlyFF=True, DEVICE=None):\n",
    "        # Handle DEVICE if not provided\n",
    "        if DEVICE is None: DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        \n",
    "        # Measure Activations (without dropout) for all images\n",
    "        storeDropout = net.getDropout()\n",
    "        net.setDropout(0) # no dropout for measuring eigenfeatures\n",
    "        allimages = []\n",
    "        activations = []\n",
    "        for images, label in dataloader:    \n",
    "            allimages.append(images)\n",
    "            images = images.to(DEVICE)\n",
    "            label = label.to(DEVICE)\n",
    "            activations.append(net.getActivations(images))\n",
    "        net.setDropout(storeDropout)\n",
    "        \n",
    "        # Consolidate variable structure\n",
    "        allinputs = []\n",
    "        if not onlyFF:\n",
    "            # Only add inputs to convolutional layers if onlyFF switch is off\n",
    "            allinputs.append(torch.flatten(torch.cat(allimages,dim=0).detach().cpu(),1)) # inputs to first convolutional layer\n",
    "            allinputs.append(torch.flatten(torch.cat([cact[0] for cact in activations],dim=0).detach().cpu(),1)) # inputs to second convolutional layer\n",
    "        allinputs.append(torch.flatten(torch.cat([cact[1] for cact in activations],dim=0).detach().cpu(),1)) # inputs to first feedforward layer\n",
    "        allinputs.append(torch.cat([cact[2] for cact in activations],dim=0).detach().cpu()) # inputs to last convolutional layer\n",
    "            \n",
    "        # Measure eigenfeatures for input to each feedforward layer\n",
    "        eigenvalues = []\n",
    "        eigenvectors = []\n",
    "        for ai in allinputs:\n",
    "            # Covariance matrix is positive semidefinite, but numerical errors can produce negative eigenvalues\n",
    "            ccov = torch.cov(ai.T)\n",
    "            crank = torch.linalg.matrix_rank(ccov)\n",
    "            w,v = sp.linalg.eigh(ccov)\n",
    "            widx = np.argsort(w)[::-1]\n",
    "            w = w[widx]\n",
    "            v = v[:,widx]\n",
    "            # Automatically set eigenvalues to 0 when they are numerical errors!\n",
    "            w[crank:]=0\n",
    "            eigenvalues.append(w)\n",
    "            eigenvectors.append(v)\n",
    "            \n",
    "        return eigenvalues, eigenvectors\n",
    "    \n",
    "    @staticmethod\n",
    "    def measureEigenFeatures(net, dataloader, onlyFF=True, DEVICE=None):\n",
    "        eigenvalues,eigenvectors = CNN2P2.inputEigenfeatures(net, dataloader, onlyFF=onlyFF, DEVICE=DEVICE)\n",
    "        \n",
    "        # Measure dot product of weights on eigenvectors for each layer\n",
    "        beta = []\n",
    "        netweights = net.getNetworkWeights(onlyFF=onlyFF)\n",
    "        for evc,nw in zip(eigenvectors,netweights):\n",
    "            nw = nw / torch.norm(nw,dim=1,keepdim=True)\n",
    "            beta.append(torch.abs(nw.cpu() @ evc))\n",
    "            \n",
    "        return beta, eigenvalues, eigenvectors\n",
    "    \n",
    "    @staticmethod\n",
    "    def avgFromFull(full):\n",
    "        numEpochs = len(full)\n",
    "        numLayers = len(full[0])\n",
    "        avgFull = torch.zeros((numLayers,numEpochs))\n",
    "        for layer in range(numLayers):\n",
    "            avgFull[layer,:] = torch.tensor([torch.mean(f[layer]) for f in full])\n",
    "        return avgFull.cpu()\n",
    "    \n",
    "    @staticmethod\n",
    "    def layerFromFull(full,layer,dim=1):\n",
    "        if dim==1: \n",
    "            return torch.cat([f[layer][:,None] for f in full],dim=dim).cpu() \n",
    "        elif dim==2:\n",
    "            return torch.cat([f[layer][:,:,None] for f in full],dim=dim).cpu() \n",
    "        else:\n",
    "            raise ValueError(\"Haven't coded layerFromFull for dimensions other than 1 or 2!\")       "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
